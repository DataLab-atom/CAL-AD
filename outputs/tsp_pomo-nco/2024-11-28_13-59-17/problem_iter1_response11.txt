```python
def _run_episode_v2(env: Env, model: Model, batch_size: int, aug_factor: int) -> float:
    """
    Runs a single episode of the TSP problem using improved sampling and action selection.

    Args:
        env: The TSP environment.
        model: The pre-trained TSP model.
        batch_size: The batch size for processing problems.
        aug_factor: Augmentation factor for data.

    Returns:
        The minimum travel distance found in the episode.
    """
    # Load TSP problems into the environment
    env.load_problems(batch_size, aug_factor)
    
    # Reset the environment and prepare the initial state
    reset_state, _, _ = env.reset()
    model.pre_forward(reset_state)

    total_reward = 0
    done = False
    visited_nodes = set()

    # Iterate until a terminal state is reached
    while not done:
        state, _, _ = env.pre_step()

        # Obtain action probabilities from the model
        selected, action_probs = model.forward(state)

        # Implement a temperature parameter to encourage exploration or exploitation
        temperature = 0.5
        selected = torch.multinomial(action_probs.softmax(dim=-1) ** (1.0 / temperature), 1).squeeze()

        # Step the environment with the selected action
        step_state, reward, done = env.step(selected)

        # Accumulate the reward; assuming it's negative distance
        total_reward += reward.item()
        visited_nodes.add(selected.item())

    # The distance is the negative of total reward collected
    return -total_reward
```
