```python
def _run_episode_v2(env: Env, model: Model, batch_size: int, aug_factor: int) -> float:
    """
    Runs a single episode of the TSP problem with enhanced heuristics.

    Args:
        env: The TSP environment.
        model: The pre-trained TSP model.
        batch_size: The batch size for processing problems.
        aug_factor: Augmentation factor for data.

    Returns:
        The minimum travel distance found in the episode.
    """
    env.load_problems(batch_size, aug_factor)
    reset_state, _, _ = env.reset()
    model.pre_forward(reset_state)

    done = False
    total_distance = 0
    action_sequence = []

    while not done:
        state, _, _ = env.pre_step()
        selected, _ = model.forward(state)

        # Store the selected action for analysis
        action_sequence.append(selected)

        step_state, reward, done = env.step(selected)
        total_distance += -reward.item()  # Accumulate negative reward (distance)

    # Optional: Implement a heuristic-based improvement step
    if len(action_sequence) > 1:
        improved_distance = heuristic_improvement(action_sequence, env)
        total_distance = min(total_distance, improved_distance)

    return total_distance

def heuristic_improvement(action_sequence, env):
    """
    Applies a heuristic to improve the travel distance based on the action sequence.

    Args:
        action_sequence: The sequence of actions taken in the TSP episode.
        env: The TSP environment.

    Returns:
        The improved distance after applying the heuristic.
    """
    # Placeholder for heuristic improvements, e.g., 2-opt or nearest neighbor
    # This function should analyze the action_sequence and return an optimized distance
    # For simplification, we just return the sum of distances as is.
    return sum(env.get_distance(a1, a2) for a1, a2 in zip(action_sequence[:-1], action_sequence[1:])) + env.get_distance(action_sequence[-1], action_sequence[0])
```
