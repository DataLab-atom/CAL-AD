```python
def _run_episode_v2(env: Env, model: Model, batch_size: int, aug_factor: int) -> float:
    """
    Runs a single episode of the TSP problem using a more structured approach.

    Args:
        env: The TSP environment.
        model: The pre-trained TSP model.
        batch_size: The batch size for processing problems.
        aug_factor: Augmentation factor for data.

    Returns:
        The minimum travel distance found in the episode.
    """
    # Load problems into the environment
    env.load_problems(batch_size, aug_factor)
    
    # Reset the environment to get the initial state
    initial_state, _, _ = env.reset()
    model.pre_forward(initial_state)

    total_reward = 0
    done = False
    current_state = initial_state

    while not done:
        # Prepare the current state for the model
        state_tensor = torch.tensor(current_state, dtype=torch.float32)
        
        # Get the model's action (next node to visit)
        action_probs = model.forward(state_tensor)
        action = torch.multinomial(action_probs, num_samples=1).item()  # Sample action based on probabilities
        
        # Step through the environment with the chosen action
        next_state, reward, done = env.step(action)
        
        # Accumulate the total reward (negative distance)
        total_reward += reward
        current_state = next_state

    return -total_reward  # Return the minimum travel distance found
```
