```python
def _run_episode_v2(env: Env, model: Model, batch_size: int, aug_factor: int) -> float:
    """
    Runs a single episode of the TSP problem with additional heuristics.

    Args:
        env: The TSP environment.
        model: The pre-trained TSP model.
        batch_size: The batch size for processing problems.
        aug_factor: Augmentation factor for data.

    Returns:
        The minimum travel distance found in the episode.
    """
    env.load_problems(batch_size, aug_factor)
    reset_state, _, _ = env.reset()
    model.pre_forward(reset_state)

    done = False
    total_distance = 0
    visited_nodes = set()
    current_node = 0  # Start from the first node
    visited_nodes.add(current_node)

    while not done:
        state, _, _ = env.pre_step()
        selected, _ = model.forward(state)
        
        # Apply heuristic: Select the nearest unvisited node
        distances = env.get_distances(current_node)
        unvisited_distances = {i: distances[i] for i in range(len(distances)) if i not in visited_nodes}
        if unvisited_distances:
            nearest_node = min(unvisited_distances, key=unvisited_distances.get)
            selected = nearest_node

        step_state, reward, done = env.step(selected)
        total_distance += reward
        current_node = selected
        visited_nodes.add(current_node)

    return -total_distance  # reward is negative distance
```
