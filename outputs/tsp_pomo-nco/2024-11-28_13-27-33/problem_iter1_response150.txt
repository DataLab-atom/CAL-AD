```python
def _run_episode_v2(env: Env, model: Model, batch_size: int, aug_factor: int) -> float:
    """
    Runs a single episode of the TSP problem with additional heuristics.

    Args:
        env: The TSP environment.
        model: The pre-trained TSP model.
        batch_size: The batch size for processing problems.
        aug_factor: Augmentation factor for data.

    Returns:
        The minimum travel distance found in the episode.
    """
    env.load_problems(batch_size, aug_factor)
    reset_state, _, _ = env.reset()
    model.pre_forward(reset_state)

    done = False
    min_distance = float('inf')
    current_path = []

    while not done:
        state, _, _ = env.pre_step()
        selected, _ = model.forward(state)
        step_state, reward, done = env.step(selected)

        # Update the current path
        current_path.append(selected.item())

        # Calculate the current distance
        current_distance = -reward.item()

        # Apply a simple heuristic: if the current distance exceeds the minimum found so far, break early
        if current_distance > min_distance:
            break

        # Update the minimum distance
        min_distance = min(min_distance, current_distance)

    # If the episode was prematurely terminated, re-run with a different heuristic
    if done:
        return min_distance
    else:
        # Apply a greedy heuristic to complete the path
        remaining_nodes = set(range(env.problem_size)) - set(current_path)
        while remaining_nodes:
            last_node = current_path[-1]
            next_node = min(remaining_nodes, key=lambda x: env.distance_matrix[last_node, x])
            current_path.append(next_node)
            remaining_nodes.remove(next_node)
            current_distance += env.distance_matrix[last_node, next_node]
            min_distance = min(min_distance, current_distance)

        return min_distance
```
