```python
def _run_episode_v2(env: Env, model: Model, batch_size: int, aug_factor: int) -> float:
    """
    Runs a single episode of the TSP problem with additional heuristics.

    Args:
        env: The TSP environment.
        model: The pre-trained TSP model.
        batch_size: The batch size for processing problems.
        aug_factor: Augmentation factor for data.

    Returns:
        The minimum travel distance found in the episode.
    """
    env.load_problems(batch_size, aug_factor)
    reset_state, _, _ = env.reset()
    model.pre_forward(reset_state)

    done = False
    min_distance = float('inf')
    current_path = []

    while not done:
        state, _, _ = env.pre_step()
        selected, _ = model.forward(state)
        step_state, reward, done = env.step(selected)

        # Update the current path
        current_path.append(selected.item())

        # Calculate the current distance
        current_distance = -reward.item()

        # Apply a simple heuristic: if the current distance exceeds the minimum found so far, break early
        if current_distance > min_distance:
            break

        # Update the minimum distance
        min_distance = min(min_distance, current_distance)

    # If the episode was prematurely terminated, re-run with a different heuristic
    if done:
        return min_distance
    else:
        # Re-run the episode with a nearest neighbor heuristic
        env.reset()
        current_node = 0
        total_distance = 0
        unvisited_nodes = set(range(env.problem_size))
        unvisited_nodes.remove(current_node)

        while unvisited_nodes:
            nearest_node = min(unvisited_nodes, key=lambda node: env.distance_matrix[current_node, node])
            total_distance += env.distance_matrix[current_node, nearest_node]
            current_node = nearest_node
            unvisited_nodes.remove(current_node)

        # Return to the starting node
        total_distance += env.distance_matrix[current_node, 0]

        return total_distance
```
