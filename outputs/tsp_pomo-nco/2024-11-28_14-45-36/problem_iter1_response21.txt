```python
def search_routine_v2(env: Env, model: Model, episodes: float, batch_size: int = 10, aug_factor: int = 8) -> float:
    """
    Executes an enhanced POMO algorithm for the TSP with additional heuristics.

    Args:
        env: The TSP environment.
        model: The pre-trained TSP model.
        episodes: Number of episodes to run.
        batch_size: Size of the problem batch.
        aug_factor: Augmentation factor for data.

    Returns:
        The total distance of the minimum valid solution.
    """
    model.eval()
    model.to(model.device)  # Ensure model is on the correct device

    env.load_problems(batch_size, aug_factor)
    total_reward = 0
    best_solution = float('inf')

    for _ in range(int(episodes)):
        rewards = _run_episode(env, model)
        total_reward += rewards.mean().item()
        torch.cuda.empty_cache()  # Clear GPU cache

        # Apply heuristic to improve solution
        current_solution = -rewards.mean().item()
        if current_solution < best_solution:
            best_solution = current_solution
            # Apply 2-opt heuristic to refine the solution
            best_solution = _apply_2_opt(env, best_solution)

    total_distance = best_solution
    return total_distance

def _apply_2_opt(env: Env, current_solution: float) -> float:
    """
    Applies the 2-opt heuristic to refine the current solution.

    Args:
        env: The TSP environment.
        current_solution: The current best solution.

    Returns:
        The refined solution after applying the 2-opt heuristic.
    """
    # Implementation of 2-opt heuristic
    # This is a placeholder and should be replaced with actual 2-opt logic
    # For example, swapping edges to reduce the total distance
    refined_solution = current_solution  # Placeholder for refined solution
    return refined_solution
```
