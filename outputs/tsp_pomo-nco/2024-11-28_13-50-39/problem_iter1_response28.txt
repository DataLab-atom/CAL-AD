```python
def _run_episode_v2(env: Env, model: Model, batch_size: int, aug_factor: int) -> float:
    """
    Runs a single episode of the TSP problem with enhanced action selection and logging.

    Args:
        env: The TSP environment.
        model: The pre-trained TSP model.
        batch_size: The batch size for processing problems.
        aug_factor: Augmentation factor for data.

    Returns:
        The minimum travel distance found in the episode.
    """
    env.load_problems(batch_size, aug_factor)
    reset_state, _, _ = env.reset()
    model.pre_forward(reset_state)

    total_reward = 0
    steps = 0
    done = False
    path = []

    while not done:
        state, _, _ = env.pre_step()
        selected, logits = model.forward(state)

        # Log action probabilities for analysis
        action_probs = torch.softmax(logits, dim=-1).detach().cpu().numpy()
        path.append(selected.detach().cpu().numpy())

        step_state, reward, done = env.step(selected)
        total_reward += reward
        steps += 1

    min_distance = -total_reward.item()  # total_reward is negative distance
    avg_action_prob = np.mean(action_probs, axis=0)

    # Optional: Print or log path and average action probabilities
    print(f"Episode completed in {steps} steps. Path: {path}")
    print(f"Average action probabilities: {avg_action_prob}")

    return min_distance
```
