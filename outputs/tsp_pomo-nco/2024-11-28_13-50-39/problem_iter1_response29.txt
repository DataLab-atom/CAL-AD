```python
def _run_episode_v2(env: Env, model: Model, batch_size: int, aug_factor: int) -> float:
    """
    Runs a single episode of the TSP problem with enhanced heuristic selections.

    Args:
        env: The TSP environment.
        model: The pre-trained TSP model.
        batch_size: The batch size for processing problems.
        aug_factor: Augmentation factor for data.

    Returns:
        The minimum travel distance found in the episode.
    """
    env.load_problems(batch_size, aug_factor)
    reset_state, _, _ = env.reset()
    model.pre_forward(reset_state)
    
    total_reward = 0
    steps_taken = 0
    max_steps = env.max_steps  # Retrieve maximum steps allowed from the environment

    done = False
    while not done and steps_taken < max_steps:
        state, _, _ = env.pre_step()
        selected, action_probs = model.forward(state)
        
        # Implementing a simple heuristic to prioritize closer nodes
        selected = selected.detach().numpy()
        if steps_taken == 0:  # If it's the first step, select the nearest point
            nearest_node = np.argmin(np.linalg.norm(env.current_positions - env.start_position, axis=1))
            selected[0] = nearest_node

        step_state, reward, done = env.step(selected)
        total_reward += reward.item()  # Accumulate total reward (negative distance)

        steps_taken += 1

    # Return the minimum distance as a positive value (reward is negative)
    return -total_reward  # total_reward is negative distance
```
