def compute_gradient(x: np.ndarray, A: List[np.ndarray], y: List[np.ndarray]) -> np.ndarray:
    """
    Compute the gradient of the smooth part of the objective function using vectorized operations.

    Parameters:
        x (np.ndarray): The solution vector.
        A (List[np.ndarray]): A list of linear transformation matrices.
        y (List[np.ndarray]): A list of observation vectors.

    Returns:
        np.ndarray: The gradient vector.
    """
    n = len(y)
    # Stack all A_i matrices and y_i vectors into a single 3D array and 2D array respectively
    A_stacked = np.stack(A, axis=0)  # Shape: (n, m, d)
    y_stacked = np.stack(y, axis=0)  # Shape: (n, m)
    
    # Compute residuals: A_i @ x - y_i for all i
    residuals = np.einsum('nmd,d->nm', A_stacked, x) - y_stacked  # Shape: (n, m)
    
    # Compute gradient contributions: 2 * A_i.T @ (A_i @ x - y_i) for all i
    gradient_contributions = 2 * np.einsum('nmd,nm->d', A_stacked, residuals)  # Shape: (d,)
    
    # Average the contributions
    gradient = gradient_contributions / n
    return gradient
